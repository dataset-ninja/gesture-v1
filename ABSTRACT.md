The **Gesture v1.0** dataset comprises 2,417 images, which collectively feature a diverse set of 4,159 labeled objects categorized into five distinct gesture classes: *one*, *two*, *three*, *four*, and *five*. To facilitate comprehensive model training and evaluation, the dataset has been thoughtfully divided into two subsets: a substantial *train* set containing 1,916 images and a *val* set with 501 images. With a strong focus on object detection and a commitment to open-source principles, the Gesture dataset serves as a robust asset for advancing research and applications in deep learning within this domain.

The dataset was collected by [opencv-webcam-script v0.5](https://gitee.com/CV_Lab/opencv_webcam), capturing every 5 frames, 5 categories, from number 1 to number 5. a total of 2500 pictures, and only took 13.55 minutes. The dataset is labeled with [label-studio](https://github.com/heartexlabs/label-studio).
